### 问题：
我有一个问卷调查数据的excel，现在要对这些数据进行一些分析工作  
数据量大概是5000条  

### 解决办法：
##### 一、对数据进行有效的存储
这里我将数据写到了mysql中的，主要是为了方便之后的操作
#### 二、对每一条评论进行情感分析
这里我使用了百度的自然语言处理中的情感倾向分析接口，  
地址: https://ai.baidu.com/docs#/NLP-API/57b9b630  
它会将评论分成三种：正向、中性、负向  
> 因为调用接口有qps限制，所以可能需要处理一段时间，  
> 我将接口返回的原始数据也进行了存储，避免重复调用  

#### 三、对评论进行分词操作，并记录词性(形容词、名词等)  
这里使用了百度的自然语言处理中的词法分析接口  
地址：https://ai.baidu.com/docs#/NLP-API/63c991b3  
它会将评论进行分词处理，并且给出了每个词的词性  
> 这里同样将接口返回的原始数据进行了存储，  
> 并且建了另一张表每个词及词性单独存储  

#### 四、将分词后的词根据评论的情感进行可视化展示  
这里使用了工具：scattertext  
地址：https://github.com/JasonKessler/scattertext  
这里最直接的使用就是看github中官方的一个demo：
https://github.com/JasonKessler/scattertext/blob/master/demo_chinese.py  
```
df['text'] = df['text'].apply(chinese_nlp)
```
里面有这么一句，这也是在进行分词，而且在点击一个关键词进行跳转显示的时候，  
就是显示的这个text字段，这就导致我不得不放弃百度的分词，  
直接在这里对评论的完整内容进行了分词  
这样保证了跳转后显示的就是评论内容  
> 但是这里有一个问题，使用demo中的分词方式，我们就不能控制词性这些东西了  
> 原本我只是想用形容词、名词、动词做关键词的。  
> 而如果我使用百度分好的词来进行处理的话，又导致跳转后显示的评论都是关键词组成的，不完整  

#### 五、优化第四步  
我发现原来可以自己设置主题，也就是设置可显示的关键字  
我就将百度处理过的词原来当主题用，但是这里又会出现一个问题，  
百度分词和程序中本身的分词不一致就导致百度分的一些词在程序本身的分词中没有，  
这样程序就会崩溃，这里我直接去改了库的源码，也就是方法:   
```get_topics_from_terms```
中进行了try操作，如果报错就```continue```。就解决了这个问题  
> 不过这里其实可以不用程序中的分词，直接用百度分好的，只不过，词与词之间用\t分隔，  
也就是tab分隔就可以
